---
title: "finalproject_Model"
author: "Superficial Intelligence (Nicholas Tanabe, Haodong Liu, Huiwen He, Xiaoyi Zhang)"
output: pdf_document
---

###ADD library(broom) or augment will not work

Another covariation of interest is the relationship between GPA and GREE scores. For this we summed GRE verbal and GRE quant to get the full GRE score, and created a scatter plot against GPA. We filtered GPA to be less than 4, as GPA of different scales are not comparable.

```{r,echo=FALSE}

grad %>% filter(!is.na(ugrad_gpa|gre_verbal|gre_quant)& ugrad_gpa < 4 & ugrad_gpa >1, is_new_gre == TRUE) %>% mutate(GRE_Total = gre_verbal + gre_quant) %>% group_by(uni_name) %>% mutate(mean_gpa = mean(ugrad_gpa), mean_GRE = mean(GRE_Total)) %>% ungroup() %>%

ggplot(aes(x = mean_GRE, y = mean_gpa)) + geom_point(aes(color = uni_name, alpha = 0.001)) +

  labs(titles = "Relationship between GPA and GRE Score",
       y = "GPA",
       x = "GRE Score",
       caption = "Figure* displays the mean GPA and the mean GRE scores of each schools in Top 10 CS program accordingly")

```


From the plot above the relationship between GPA and GRE seems to be positively correlated but is not as strong of a relationship as we expected. Most GPAs tend to be on the higher range: people densely fall into the range between 3.5 and 3.75; GRE scores seem to be more variable across application: scores for all applicants concentrate in the range between 300 and 325 with more outliers. 


#Research Questions and Modeling Methods(Think we should move this in the top)

Our general research question remains the same as in deliverable one: "How do different variables relate to admission decision?" However, through our exploratory data analysis, we realised that the full dataset may be too large to get a clear picture of how different factors affect admissions decision. Because the full dataset contains a wide variety of schools and graduate programs (which would all have different standards for admission and a variety of interactions), we decided to narrow down the dataset to just the top 10 most popular Computer Science programs. The reason for this is that factors related to admission are likely not comparable accross different schools (e.g. highly selective schools vs high acceptance rate schools) or different programs (e.g. factors that may be important to Computer Science programs would likely differ from a Fine arts program). 



```{r,echo=FALSE}

#Top 10 Most Popular Computer Science Programs in Data

(top10 <-merge(grad1,grad2,by =("uni_name")) %>% mutate(rate = accepted/n) %>% filter(n>100) %>% arrange(desc(n)) %>% head(10))

top10 <- head(top10,10)$uni_name

grad <- subset(grad, uni_name %in% top10)

grad <- grad[complete.cases(grad), ]

#Clean Data

grad <- grad[complete.cases(grad[,-14]), ] %>% filter(is_new_gre == TRUE, ugrad_gpa <=4,status!="Other")%>% mutate(decision1 = (decision=="Accepted"), GRE_Total = gre_verbal + gre_quant)

```


In order to model the probability of acceptance, we decide to use a logisitic regression, as the result we want to model is binary (Accepted vs Not Accepted). For our covariates, we hypothesize that GPA, GRE Scores, and student status (American vs International Student) play a significant role in determining the admission decision. We also suspect that there may be interactions between student status and scores. In order to select variables, we start with a full model containing all of these variables and use the backwards elimination method of stepwise regression to fit a "best" model.



#Fitting the Model

We decided to fit a logistics model to better understand predictor variables and the acceptance rate, predictor variables including GRE total score(Gre verbal +GRE quant), undergraduate GPA, GRE writing score, and student status.



```{r, include= FALSE}

#model w/o interaction

full_mod <- glm(decision1 ~ ugrad_gpa+GRE_Total+gre_writing+status-1, data = grad, family = binomial)

gradmodel <- step(full_mod)

```

```{r, echo=False}

summary(gradmodel)

```

#Interpret the model without assumption

In the model that does not include interaction terms: 

The regression coefficient for ugrad_gpa is $\hat{\beta_(ugradgpa)} = 1.168482$, which indicates that for a one-unit increase in undergraduate GPA the logit-transformed probability of getting accepted to the program will increase by 1.15. $\hat{\beta_(GREtotal)} = 0.030744$ is the coefficient for predictor GRE_Total showing that for a one-unit increase in GRE total scores the log odds will increase by 0.03. $\hat{\beta_(GREwriting)} = -0.359779$ shows that GRE writing score is negatively related with the probability of acceptance, and for every one unit increase in writing score leads to a 0.36 drop in log odds. 

If the applicant is an American students, our model predicts a drop equals to $\hat{\beta_(American)} = -12.892745$ in the log odds, holding all other independent variables constant. If the aaplicant is a international student, log odds decreases by $\hat{\beta_(International)} = -13.302409$, and if the student has earned a US degree, log odds drops by $\hat{\beta_(USdegree)} = -12.981663$.



```{r,echo=FALSE}

# prediction of model without interaction term

mod_coef_n <- coef(gradmodel)

prediction_american_n <- mod_coef_n[1]*mean(grad$ugrad_gpa)+mod_coef_n[2]*mean(grad$GRE_Total)+mod_coef_n[3]*mean(grad$gre_writing)+mod_coef_n[4]

exp(prediction_american_n) / (1 + exp(prediction_american_n))

prediction_inter_n <- mod_coef_n[1]*mean(grad$ugrad_gpa)+mod_coef_n[2]*mean(grad$GRE_Total)+mod_coef_n[3]*mean(grad$gre_writing)+mod_coef_n[5]

exp(prediction_inter_n) / (1 + exp(prediction_inter_n))

prediction_inter_us_n <- mod_coef_n[1]*mean(grad$ugrad_gpa)+mod_coef_n[2]*mean(grad$GRE_Total)+mod_coef_n[3]*mean(grad$gre_writing)+mod_coef_n[6]

exp(prediction_inter_us_n) / (1 + exp(prediction_inter_us_n))

```

Using same mean level GPA, GRE total score and writing score, our simple logistic model predicts that the probability of an American student getting accepted to the program is 49.1% and the probability for an international student without a US degree and one with a US degree is 39% and 46.9% respectively.

##Assumption_w/o interation(whether the assumptions fit or not)
Next, to ensure that our models are valid, we check the assumptions of logistic regression:

1. Outcome is binary
2. Linear relationship between the logit of the outcome and each predictor variables
3. No influential values
4. No high intercorrelations

```{r,echo=FALSE}

library(broom)

p <- predict(full_mod, type = "response")

grad_mod <- grad %>%

  select_if(is.numeric) %>% select(-1, -gre_quant, -gre_verbal)

predictors <- colnames(grad_mod) 

grad_mod <- (grad_mod %>%

  mutate(logit = log(p/(1-p))) %>%

  gather(key = "predictors", value = "value", -logit))

# check linearity between x and logit of the outcome

ggplot(grad_mod, aes(logit, value))+

  geom_point(size = 0.5, alpha = 0.5) +

  geom_smooth(method = "loess") + 

  theme_bw() + 

  facet_wrap(~predictors, scales = "free_y") +
  labs(titles = "Linearity of Numerical Variables",
       caption = "Figure* plots the linearity between the logit of outcome and the value of numerical varibales")

# check influencial values

# top3 largest values

plot(full_mod, which = 4, id.n = 3,
     xlab = "Observation Index",
     sub = "Figure* describes the cook's distance for all observations in the dataset")

# plot the standardized residual

data <- augment(full_mod) %>% 

  mutate(index = 1:n())

data %>% top_n(3, .cooksd)

ggplot(data, aes(index, .std.resid)) + 

  geom_point(aes(color = decision1)) +

  theme_bw() +
  labs(titles = "Standardized Residuals",
       x = "index",
       y= "Standard Deviation",
       caption = "Figure* plots the distance between predicted value and residuals")

# if standardized residual is greater than 3 -> Influential

data %>% 

  filter(abs(.std.resid) > 3)

# correlation covariance matrix

grad_noNA = grad %>% filter(is.na(ugrad_gpa) == FALSE, is.na(gre_verbal) ==FALSE,  is.na(gre_quant) ==FALSE, is.na(gre_writing) ==FALSE)

(grad_noNA = grad_noNA %>% mutate(gre_total = gre_verbal + gre_quant))

(my_data1 <- grad_noNA[, c(8,11,17)])

my_data2 <- grad_noNA[, c(8,9,10,11)]

#This is the correlation matrix for ugrad_gpa, gre_total, gre_writing

(rcorr(as.matrix(my_data1)))

#This is the correlation matrix for ugrad_gpa, gre_verbal, gre_quant, gre_writing

(rcorr(as.matrix(my_data2)))

```

First, since we set the accepted decision as dependent variables and the decision is binary, either 1, accepted or 0, rejected. Therefore, the predicted probability is bind within the interval between 0 and 1. It meets the first assumption of dependent variable to be binary. 

Second, logistic regression also assumes the linearity of independent variables.As shown in "The linearity of independent variables", the logit of GRE and undergraduate gpa are fairly linear to the accepted probability in logit scale. However, the scatter plots of gre_writing fits a parabola, instead of a linear line.

Third, some outliers may be influential enough to alter the quality of the logistic regression model. Therefore, we calculated the Cook's distance for each points; the higher the leverage and residuals of that point, the higher its Cook’s distance. As demonstrated in Cook's distance graph, there exist couple of spikes in the graph. To further investigate this issue, the deviance residuals plots has ben constructed. Since it does not have any observations whose cook's value is large than 3, we conclude that the dataset does not have any influential outliers. 

Last but not least, from the covariance matrix, we can tell that each term are corrlated with each other since its p value is near 0. Therefore, we incorporate interaction terms in our further model to overcome this disadvantage.


###ADD THE REASON WHY WE DECIDE TO INTERACT STATUS WITH THE REST OF THE VARIABLES

###TRANSITION


###Model With Interaction

```{r,include=FALSE}

#model with interaction

full_mod_int <- glm(decision1 ~ (ugrad_gpa+GRE_Total+gre_writing)*status-1, data = grad, family = binomial)

gradmodel_int <- step(full_mod_int)

```

```{r,echo=FALSE}

summary(gradmodel_int)

```

One interesting observation we see is that there is an interaction between GRE Writing and Student Status. This could be due to varying standards for writing ability based on Student Status. American students may be held to a higher standard for writing quality than international students, which is to be expected.


# Coefficient Interpretation

In the model that includes interaction:

The regression coefficient for ugrad_gpa is $\hat{\beta_(ugradgpa)} = 1.146643$ meaning that for a one-unit increase in undergraduate GPA the logit-transformed probability of getting accepted to the program will increase by 1.15. Predictor GRE_Total has a coefficient $\hat{\beta_(GREtotal)} = 0.031106$, showing that for a one-unit increase in GRE total scores the log odds will increase by 0.03. We also include categorical variable status representing the applicant's status. The corresponding coefficient $\hat{\beta_(American)} = -13.403241$ shows that if the applicant is an American student, the log odds will decrease by 13.4, holding all other independent variables constant, $\hat{\beta_(International)} = -12.782405$ shows the change in log odds given the student is an international student, and $\hat{\beta_(USdegree)} = -15.544697$ shows the change in log odds given the student is an international student with a US degree.

$\hat{\beta_(GREwriting)} = -0.267686$ is the regression coefficients for GRE writing score, and $\hat{\beta_(GREwriting:International)} = -0.252731$ and for the interaction term $\hat{\beta_(GREwriting:USdegree)} = 0.540781$ are the coefficients of GRE writing scores with respect to students status. However, the hypothesis tests for coefficient indicates that those terms would not significantly impact the prediction of our model. 


```{r,echo=FALSE}

# prediction of model with interaction term

mod_coef <- coef(gradmodel_int)

prediction_american <- mod_coef[1]*mean(grad$ugrad_gpa)+mod_coef[2]*mean(grad$GRE_Total)+mod_coef[3]*mean(grad$gre_writing)+mod_coef[4]

exp(prediction_american) / (1 + exp(prediction_american))

prediction_inter <- mod_coef[1]*mean(grad$ugrad_gpa)+mod_coef[2]*mean(grad$GRE_Total)+mod_coef[3]*mean(grad$gre_writing)+mod_coef[5]+mod_coef[7]

exp(prediction_inter) / (1 + exp(prediction_inter))

prediction_inter_us <- mod_coef[1]*mean(grad$ugrad_gpa)+mod_coef[2]*mean(grad$GRE_Total)+mod_coef[3]*mean(grad$gre_writing)+mod_coef[6]+mod_coef[8]

exp(prediction_inter_us) / (1 + exp(prediction_inter_us))

```

We next check the prediction for the probability of a student getting accepted at mean level GPA, GRE total score, and writing score. According to our model that includes interaction, there's a 47.9% chance that the student will be admitted to the program if the student is an American student, and 57% and 15.6% respectively if the student is an international student or an international student with a US degree.



##Assumption 

Next, to ensure that our models are valid, we check the assumptions of logistic regression:

1. Outcome is binary
2. Linear relationship between the logit of the outcome and each predictor variables
3. No influential values
4. No high intercorrelations

```{r,echo=FALSE}

# 1. outcome is binary

# 2. linear relationship between the logit of the outcome and each predictor variables

# 3. no influential values

# 4. no high intercorrelations

p_int <- predict(full_mod_int, type = "response")

grad_mod_int <- grad %>%

  select_if(is.numeric) %>% select(-1, -gre_quant, -gre_verbal)

predictors_int <- colnames(grad_mod_int) 

grad_mod_int <- (grad_mod_int %>%

  mutate(logit = log(p_int/(1-p_int))) %>%

  gather(key = "predictors_int", value = "value", -logit))

# check linearity between x and logit of the outcome

ggplot(grad_mod_int, aes(logit, value))+

  geom_point(size = 0.5, alpha = 0.5) +

  geom_smooth(method = "loess") + 

  theme_bw() + 

  facet_wrap(~predictors_int, scales = "free_y") +
  labs(titles = "Linearity of Numerical Variables",
       caption = "Figure* plots the linearity between the logit of outcome and the value of numerical varibales")

# check influencial values

# top3 largest values

plot(full_mod_int, which = 4, id.n = 3,
     xlab = "Observation Index",
     sub = "Figure* describes the cook's distance for all observations in the dataset")

# plot the standardized residual

data_int <- augment(full_mod_int) %>% 

  mutate(index = 1:n())

data_int %>% top_n(3, .cooksd)

ggplot(data_int, aes(index, .std.resid)) + 

  geom_point(aes(color = decision1)) +

  theme_bw() +
  
  labs(titles = "Standardized Residuals",
       x = "index",
       y= "Standard Deviation",
       caption = "Figure* plots the distance between predicted value and residuals")

# if standardized residual is greater than 3 -> Influential

data_int %>% 

  filter(abs(.std.resid) > 3)

#Correlation matrix


grad_noNA = grad %>% filter(is.na(ugrad_gpa) == FALSE, is.na(gre_verbal) ==FALSE,  is.na(gre_quant) ==FALSE, is.na(gre_writing) ==FALSE)

(grad_noNA = grad_noNA %>% mutate(gre_total = gre_verbal + gre_quant))

my_data1 <- grad_noNA[, c(8,11,14)]

my_data2 <- grad_noNA[, c(8,9,10,11)]

#(rcorr(as.matrix(my_data)))

#This is the correlation matrix for ugrad_gpa, gre_verbal, gre_quant, gre_writing

(rcorr(as.matrix(my_data2)))

```

First, since we set the accepted decision as dependent variables and the decision is binary, either 1, accepted or 0, rejected. Therefore, the predicted probability is bind within the interval between 0 and 1. It meets the first assumption of dependent variable to be binary. 

Second, logistic regression also assumes the linearity of independent variables.As shown in "The linearity of independent variables", the logit of GRE is quite linear to the accepted probability in logit scale. Even though there exists an U-shaped trend at the end of the parabala, the majority of gpa points associated linearly to the logit outcome of undergraduate gpa. However, the scatter plots of gre_writing shows non_linearity, similar to a cubic term.

Third, some outliers may be influential enough to alter the quality of the logistic regression model. Therefore, we calculated the Cook's distance for each points; the higher the leverage and residuals of that point, the higher its Cook’s distance. As demonstrated in Cook's distance graph, there exist couple of spikes in the graph. To further investigate this issue, the deviance residuals plots has ben constructed. Since it does not have any observations whose cook's value is large than 3, we conclude that the dataset does not have any influential outliers. 

Last but not least, since the variables are intercorrlated, we take this into consideration and use interaction terms to overcome this issue.


#Tests for Significant Interaction

```{r,echo=FALSE}

gg_int <- grad %>%

 mutate(pred = predict(gradmodel_int,

 type = "response")) #%>% select(decision, pred)


gg <- grad %>%

 mutate(pred = predict(gradmodel,

 type = "response")) #%>% select(decision, pred)


(wr = gg_int %>% mutate(gre_writing = as.integer(gre_writing)))

interaction.plot(x.factor     = wr$status,

                 trace.factor = wr$gre_writing, 

                 response     = wr$pred, 

                 fun = mean,

                 type="b",

                 col=c("black","red","green","blue","orange"),  ### Colors for levels of trace var.

                 pch=c(19),             ### Symbols for levels of trace var.

                 fixed=TRUE,                    ### Order by factor order in data

                 leg.bty = "o",

                 main = 'Interaction Plot between GRE Writing Scores and Status',

                 xlab = 'Status',

                 ylab = 'GRE Writing',
                 sub = "Figure* describes the interaction graph under different gre writing score")

#Think jerry adds the sub here

```



The plot suggests that the effect of GRE writing is not consistent across all three groups of students.  For example, a writing score of 5 showed the greater mean probability of acceptance for American and international students with US Degree. for international student, a writing score of 2 gives the highest chance of acceptance. This suggests there may be a meaningful or significant interaction effect.

Next, we plot box plots of admission decisions vs predicted probabilities to assess the predictive power of our models.



```{r,echo=FALSE}

p1 <- grad %>%

 mutate(pred = predict(gradmodel_int,

 type = "response")) %>%

 ggplot(aes(factor(decision1), pred)) +

 geom_boxplot() +

 geom_point(aes(color = status),

 position = "jitter") +

 labs(title = "Model With Interaction",

      x = "Admission Decision",

      y="Predicted Probability of Admission", 
      caption = "Figure* is the boxplot for our model outcome") +

      scale_x_discrete(labels = c('Rejected','Accepted')) +

  theme(legend.position="bottom")

p2 <- grad %>%

 mutate(pred = predict(gradmodel,

 type = "response")) %>%

 ggplot(aes(factor(decision1), pred)) +

 geom_boxplot() +

 geom_point(aes(color = status),

 position = "jitter") +

 labs(title = "Model Without Interaction",

      x= "Admission Decision",

      y="") +

      scale_x_discrete(labels = c('Rejected','Accepted')) +

  theme(legend.position="bottom", legend.title = element_blank())


grid.arrange(p1, p2, ncol = 2)

```

In model without interaction, the mean of predicted probabilities of rejected students is around 0.41, while the mean of predicted probabilities of accepted students is around 0.43, which is slightly higher than the mean of predicted probabilities of rejected students. Since their interval are overlapped, it means that the prediction may not be significant enough to explain the success of a student being accepted. In addition, the plots are fairly scattered, meaning that there does not exist a certain pattern to explain the trend.

In model with interaction, the mean of predicted probabilities of rejected students is around 0.4, while the mean of predicted probabilities of accepted students is around 0.45, which is slightly higher than the mean of predicted probabilities of rejected students. Since their interval are overlapped, it means that the prediction may not be significant enough to explain the success of a student being accepted. However, the plots are more densely concentrated than the one without interation.

In the assumptions for two models, however, numerical variables in assumptions of model without interatction appear more linear than the one in model with interaction.





#Test for the inclusion of a Categorical Variable

```{r,echo=FALSE}

(anova( full_mod, full_mod_int, test = "Chisq"))

(Anova(full_mod_int, type = "II"))

```

**H~0~:** full_mod = full_mod

**H~a~:** full_mod = full_mod_int

Significance Level: 0.05

Pr(>Chi) for two models is 0.1581, which is bigger than siginificant level 0.05. Therefore, two models are not significantly different.

Pr(>Chi) for ugrad_gpa, GRE_Total, gre_writing and status are all smaller than siginificant level 0.05, while all the interaction effect is not signficant. Therefore, the anova table indicates that the main effect are significant, and interaction effect is not significant.

# Discussion

From this exploratory data analysis, we confirm many of the hypotheses that we had going into this project. For example, we confirmed our hypotheses that more students apply in the fall semester than the spring semester and that the majority of students applying (or reported) are American. We confirmed relationships between variables such as GPA and GRE scores. We learned several things as well. For example, we learned the distribution of GPA is left skewed, and GRE scores have an abnormal distribution, with several "spikes" among certain scores. We were surprised to see that American students tended to have higher rates of acceptance than international students.


While this is a very interesting and robust dataset to analyze, there are also several problems we encountered. First, the dataset is not very clean, as it is self-reported. For example, the names of Universities and Majors are not always consistent. For example, some students may write "Boston University (BU)" while others write the name of the specific college at BU such as "Boston University - Metropolitan College." We also noticed that scales of scores and GPA are not always consistent. For example, GPA is most often reported on a 4.0 scale, however, some responses included other scales such as 10 point scale. These will all be problems that we have to work around when going into modeling.

From the analysis above, we see that while GPA, GRE Scores, and Student Status have a significant affect on admissions decisions, they alone are not great predictors for admission results. We see from the box plots that while the model had a higher average predicted probability for students that were actually accepted, there is too much variance in the resulted predictions. This result is likely due to the fact that the dataset is missing many variables that may also be important for admission decisions, such as research experience, reccomendations, reputation of undergraduate institution and so on. While it may be possible to extract this information from the 'comments', many observations did not include any comments and many more did not mention these factors in the comments. This leads us to believe that the admissions process is more than just a "numbers game," and likely includes many "intangibles" in order to determine the ultimate admission result of each student.